# Coordinate System

#opengl/coordinate

OpenGl希望在vertex shader运行之后所有顶点在标准设备坐标中(-1.0 - 1.0)，范围外的坐标是看不见的。

我们通常做的是 --- 指定我们自己的范围坐标，在shader中将坐标转化为标准坐标(NDC)，然后使用NDC提供的光栅化器转化为像素

将坐标转化为NDC通过是一步一步来的，我们将一个对象的顶点转换为几个坐标系，然后最终将它们转换为NDC。

好处：有一些操作或者计算，在特定的坐标系中更加容易

5个重要的坐标系

- Local space (or Object space)
- World space
- View space (or Eye space)
- Clip space
- Screen space

这些是顶点在被最终输出为NDC之前需要转换的坐标。

## The global picture

为了将坐标从一个空间转换到下一个坐标空间，我们将使用几个转换矩阵，其中最重要的是model, view and projection matrix。

vertex实现开始在local space --- world coordinates --- view coordinates ---- clip coordinate  ---- screen cprrdomate

<img src="https://s2.loli.net/2023/03/01/OFADMCmiZPGL2cU.png" style="zoom:50%;" />

1. local coordinates --- 局部坐标 ---- 局部坐标是相对于局部顶点的坐标：物体开始的坐标
2. 之后将local coordinate 转化为 world-space coordinate（代表大世界）。这个坐标系相对对于一个全局的坐标，同时很多其他物体也是相对于这个坐标。
3. 下一步将world-space coordinate 转化为 view space，这样每个坐标都是从摄像机或观众的角度看到的
4. 之后我们希望把这些物体映射到clip coordinate。clip coordinate的范围是-1.0 - 1.0，这一步会决定哪些vertex会出现在屏幕上，如果使用透视投影，投影到剪辑空间坐标可以添加透视。
5. 最后我们将clip space --- screen space，使用viewport transform技术，这一步将-1.0 - 1.0的坐标转化为`glViewPoint`定义的坐标中，随后将坐标发送到光栅化器中转化为fragment

## local space

#opengl/coordinate/local 

就是我们模型自己的初始位置！！！

The vertices of the container we've been using were specified as coordinates between `-0.5` and `0.5` with `0.0` as its origin. These are local coordinates.

## World space

#opengl/coordinate/world

为了方便表示不同物体之间的位置，我们使用world space。通过model matrix来实现。

模型矩阵是一个转换矩阵，它可以平移、缩放和/或旋转您的对象，以将其放置在世界上它们所属的位置/方向。把它想象成通过缩小比例来改造房子(可能在local place中很大，)把它转换成一个郊区小镇，并在y轴上向左旋转一点，这样它就能与邻近的房子整齐地匹配。您可以将上一章中的矩阵作为一种模型矩阵来放置场景中的容器；我们将容器的局部坐标转换到场景/世界中的某个不同位置。

## View space

#opengl/coordinate/view

The view space is what people usually refer to as the camera of OpenGL (it is sometimes also known as camera space or eye space).

The view space is the result of transforming your world-space coordinates to coordinates that are in front of the user's view. 

因此，视图空间是从相机的视点看到的空间。这通常是通过组合平移和旋转来实现的，以平移/旋转场景

变换到镜头前。这些组合转换通常存储在一个视图矩阵中，该视图矩阵将世界坐标转换为视图空间。在下一章中，我们将广泛讨论如何创建这样一个视图矩阵来模拟相机。

## Clip space

#opengl/coordinate/clip

在每个顶点着色器运行结束时，OpenGL期望坐标在一个特定的范围内，任何落在这个范围之外的坐标都将被剪切。被剪切的坐标将被丢弃，因此剩余的坐标最终将作为屏幕上可见的片段。这也是剪辑空间名称的来源。

因为指定所有可见坐标都在-1.0和1.0范围内并不直观，所以我们指定了自己的坐标集，并按照OpenGL的要求将它们转换回NDC。

为了将顶点坐标从视图转换到剪辑空间，我们定义了一个所谓的投影矩阵，它指定了一个坐标范围，例如每个维度的-1000和1000。然后，投影矩阵将这个指定范围内的坐标转换为标准化的设备坐标(-1.0,1.0)(不是直接转换，中间有一个叫做Perspective Division的步骤)。

所有超出这个范围的坐标将不会被映射到-1.0到1.0之间，因此会被剪切。在我们在投影矩阵中指定的这个范围内，(1250,500,750)的坐标将不可见，因为x坐标超出了范围，因此在NDC中被转换为高于1.0的坐标，因此被剪切。

> 注意，如果一个原语只有一部分，例如一个三角形在剪切体积之外，OpenGL将把这个三角形重建为一个或多个三角形，以适应剪切范围。

投影矩阵创建的这个观察框被称为平截头体，在这个平截头体内结束的每个坐标都将在用户的屏幕上结束。将指定范围内的坐标转换为可轻松映射到2D视图空间坐标的NDC的整个过程称为投影，因为投影矩阵将3D坐标投影到易于生成的2D标准化设备坐标。

一旦将所有顶点转换为剪辑空间，就执行称为透视分割的最终操作，其中我们将位置向量的x、y和z分量除以向量的齐次w分量；透视分割是将4D剪辑空间坐标转换为3D标准化设备坐标的过程。此步骤在顶点着色器步骤结束时自动执行。

在这个阶段之后，生成的坐标被映射到屏幕坐标(使用glViewport的设置)并转换为片段。

将视图坐标转换为剪辑坐标的投影矩阵通常采用两种不同的形式，每种形式都定义了自己的唯一截锥。我们既可以创建正交投影矩阵（orthographic ），也可以创建透视投影矩阵（perspective）。

### orthographic projection

#opengl/coordinate/view/orthographic_projection

<img src="https://s2.loli.net/2023/05/12/8erIZca3oLiGONm.png" style="zoom:50%;" />

正交投影矩阵定义了一个类似立方体的截锥框，该截锥框定义了裁剪空间，该裁剪空间外的每个顶点都被裁剪。

在创建正交投影矩阵时，我们指定可见截体的宽度、高度和长度。这个截体内的所有坐标经过矩阵变换后都将在NDC范围内，因此不会被剪切。截锥看起来有点像一个容器

![1](https://s2.loli.net/2023/03/01/p8JkKrFqLtgNvsZ.png)

锥体由宽度---高度---near plane --- far plane 决定

near plane前和far plane后的物体会被裁剪掉。

正交平截头体直接将平截头体内的所有坐标映射到标准化的设备坐标，没有任何特殊的副作用，因为它不会接触变换向量的w分量；如果w分量保持等于1.0，透视分割不会改变坐标。

我们可以使用glm内置的函数来创建正交映射矩阵

```c++
glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);
```

- 第一二个参数代表坐标系的左右
- 第三四个参数代表坐标系的底部和顶部
- 前四个参数我们定义了near和far plane的大小。
- 第五六个参数定义了两个平面之间的距离

这个特定的投影矩阵将这些x、y和z范围值之间的所有坐标转换为规范化的设备坐标。

但是正交投影没有考虑到透视！！！

### Perspective projection

#opengl/coordinate/view/Perspective_projection

透视映射矩阵的作用就是模仿透视

在映射过程会改变w值 --- 物体越远，w值越高。一旦坐标系被转换到clip space中，那么他们会被映射到-w - w中(任何超过这一范围的就会被剪切掉)。

OpenGL要求作为最终顶点着色器输出的可见坐标介于-1.0和1.0之间，因此，一旦坐标位于剪辑空间中，透视分割将应用于剪辑空间坐标：

![image.png](https://s2.loli.net/2023/03/01/8BjZDRXeVTWfu93.png)

顶点坐标的每个分量都除以其w分量，从而使顶点距离观察者越远，顶点坐标越小。这是w分量之所以重要的另一个原因，因为它可以帮助我们进行透视投影。然后，得到的坐标在标准化的设备空间中。

透视映射矩阵

```c++
glm::mat4 proj = glm::perspective(glm::radians(45.0f),(float)width/(float)height, 0.1f, 100.0f);
```

`glm::perspective`也是创造一个锥体来定义可视区域，锥体外的会被裁剪。透视平截头体可以被可视化为一个形状不均匀的长方体，从该长方体中的每个坐标都将被映射到剪辑空间中的一个点。透视平截头体的图像如下所示：

<img src="https://s2.loli.net/2023/03/01/8uOcFW6TZBA5CrY.png" style="zoom:50%;" />

第一个值定义了fov值---- field of view 并且设置了可是空间的大小。实际情况中，使用45度，但也会有很高的值。第二个参数设置纵横比，它是通过视口的宽除以高计算出来的。最后两个值设置near/far plane。We usually set the near distance to `0.1` and the far distance to `100.0`. All the vertices between the near and far plane and inside the frustum will be rendered.

> 如果我们将near plane的值设置的过远如 10.0 那么我们到这的距离之间的东西就会被删除。这可以给你一个视觉效果，你可能在电子游戏中见过，当你不舒服地靠近某些物体时，你可以看穿它们。

在使用正交投影的时候，所有的顶点坐标直接映射到clip space(因为w恒定为1)。正交投影中远处的物体和近处的物体是一样大的。因此正交投影通常被用为2D渲染。

像Blender这样用于3D建模的应用程序有时会使用正字法投影进行建模，因为它可以更准确地描绘每个对象的尺寸。下面你将看到Blender中两种投影方法的比较

![](https://s2.loli.net/2023/03/02/7oYbG5hB1d9kqDK.png)

## Putting it all together

我们为所有的变换步骤创造了变换矩阵。一个顶点坐标变换到clip spce如下

![](https://s2.loli.net/2023/03/02/8eEQab6TkfHcjMg.png)

结果最后会被送到`gl_Position`中，opengl会自动执行。OpenGL将自动执行透视分割和剪切。

> 顶点着色器的输出要求坐标在剪辑空间中，这就是我们刚才对变换矩阵所做的。然后OpenGL对剪辑空间坐标执行透视分割，将其转换为标准化的设备坐标。然后OpenGL使用glViewPort中的参数将标准化设备坐标映射到屏幕坐标，其中每个坐标对应于屏幕上的一个点（在我们的例子中是800x600屏幕）。此过程称为视口变换。

## 3D

为了进行3D渲染，我们首先需要模型矩阵，包含平移，缩放/旋转(用来变换所有全局的物体)。

现在我们通过在x轴旋转来让我们的平面看起来平铺在平面上

```c++
glm::mat4 model = glm::mat4(1.0f);
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0f, 0.0f, 0.0f)); 
```

将顶点坐标和模型矩阵相乘，我们将顶点坐标转换为世界坐标后我们的平面平铺在地板上，因此代表了世界中的平面。

之后我们需要创建view matrix，我们希望在场景中稍微向后移动，以便对象变得可见(当在世界空间中我们位于原点(0,0,0)时)。要在场景中移动，请考虑以下内容

- To move a camera backwards, is the same as moving the entire scene forward.

这就是view matrix做的事，我们将整个场景反向移动到我们想要相机移动的地方。

因为我们想向后移动，而且OpenGL是一个右手系统，所以我们必须在正z轴上移动。我们通过将场景平移到负z轴来做到这一点。这给人一种我们在倒退的印象。

> 右手坐标
>
> - Stretch your right-arm along the positive y-axis with your hand up top.
> - Let your thumb point to the right.
> - Let your pointing finger point up.
> - Now bend your middle finger downwards 90 degrees.
>
> ![](https://s2.loli.net/2023/03/05/mjezdvr97K5cYw3.png)

```c++
glm::mat4 view = glm::mat4(1.0f);
// note that we're translating the scene in the reverse direction of where we want to move
view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f)); 
```

最后我们需要创建的事映射矩阵，使用透视映射，因此我们需要如下定义

```c++
glm::mat4 projection;
projection = glm::perspective(glm::radians(45.0f), 800.0f / 600.0f, 0.1f, 100.0f);
```

我们创建了变换矩阵，我们通过uniform将他们传入其中，并在gpu中相乘。

```glsl
#version 330 core
layout (location = 0) in vec3 aPos;
...
uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;

void main()
{
    // note that we read the multiplication from right to left
    gl_Position = projection * view * model * vec4(aPos, 1.0);
    ...
}
```

我们也需要将我们的矩阵送入opengl中。

```c++
int modelLoc = glGetUniformLocation(ourShader.ID, "model");
glUniformMatrix4fv(modelLoc, 1, GL_FALSE, glm::value_ptr(model));
... // same for View Matrix and Projection Matrix
```

## more 3D

现在仅仅是一个平面，To render a cube we need a total of 36 vertices (6 faces * 2 triangles * 3 vertices each). 36 vertices are a lot to sum up so you can retrieve them from [here](https://learnopengl.com/code_viewer.php?code=getting-started/cube_vertices).

这个正方体随着时间转动

```c++
model = glm::rotate(model, (float)glfwGetTime() * glm::radians(50.0f), glm::vec3(0.5f, 1.0f, 0.0f));  
```

And then we'll draw the cube using glDrawArrays (as we didn't specify indices), but this time with a count of 36 vertices.

```c++
glDrawArrays(GL_TRIANGLES, 0, 36);
```

它确实有点像立方体，但有点不对劲。立方体的某些边被绘制在立方体的其他边上。发生这种情况是因为当OpenGL逐三角形、逐片段地绘制立方体时，它将覆盖之前可能已在其中绘制的任何像素颜色。由于OpenGL无法保证渲染的三角形的顺序（在同一个绘制调用中），所以即使一个三角形明显位于另一个三角形的前面，也会在另一个的上面绘制一些三角形。

Luckily, OpenGL stores depth information in a buffer called the z-buffer that allows OpenGL to decide when to draw over a pixel and when not to. Using the z-buffer we can configure OpenGL to do depth-testing.

### Z-buffer

#opengl/z-buffer

opengl将所有深度信息存储在z-buffer中，glfw会自动的帮我们创建。在每一个片段中，都会存储深度，每当一个片段想要输出颜色的时候，opengl就会对比深度，如果当前片段位于另一个片段的后面，它将被丢弃，否则将被覆盖。这个过程被称为深度测试，由OpenGL自动完成。

为了确保opengl开启深度测试，我们需要使用`glEnable`。The glEnable and glDisable functions allow us to enable/disable certain functionality in OpenGL

```c++
glEnable(GL_DEPTH_TEST);  
```

由于我们使用了深度缓冲区，所以我们还希望在每次渲染迭代之前清除深度缓冲区(否则前一帧的深度信息仍保留在缓冲区中)。就像清除颜色缓冲区一样，我们可以通过在glClear函数中指定depth buffer BIT位来清除深度缓冲区

```c++
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
```

### more cubes

画出10个cubes，我们不需要改变shader只需要定义不同的model matrix。

- 定义translation vector

```c++
glm::vec3 cubePositions[] = {
    glm::vec3( 0.0f,  0.0f,  0.0f), 
    glm::vec3( 2.0f,  5.0f, -15.0f), 
    glm::vec3(-1.5f, -2.2f, -2.5f),  
    glm::vec3(-3.8f, -2.0f, -12.3f),  
    glm::vec3( 2.4f, -0.4f, -3.5f),  
    glm::vec3(-1.7f,  3.0f, -7.5f),  
    glm::vec3( 1.3f, -2.0f, -2.5f),  
    glm::vec3( 1.5f,  2.0f, -2.5f), 
    glm::vec3( 1.5f,  0.2f, -1.5f), 
    glm::vec3(-1.3f,  1.0f, -1.5f)  
};
```

现在，在渲染循环中，我们希望调用glDrawArrays 10次，但这次每次在发出绘制调用之前，都会向顶点着色器发送不同的模型矩阵。我们将在渲染循环中创建一个小循环，每次使用不同的模型矩阵渲染对象10次。注意，我们还为每个容器添加了一个小的唯一旋转。

```c++
glBindVertexArray(VAO);
for(unsigned int i = 0; i < 10; i++)
{
    glm::mat4 model = glm::mat4(1.0f);
    model = glm::translate(model, cubePositions[i]);
    float angle = 20.0f * i; 
    model = glm::rotate(model, glm::radians(angle), glm::vec3(1.0f, 0.3f, 0.5f));
    ourShader.setMat4("model", model);

    glDrawArrays(GL_TRIANGLES, 0, 36);
}
```

